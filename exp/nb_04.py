
#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: dev_nb/04_callbacks.ipynb
from exp.nb_03 import *
import torch.nn.functional as F

class DataBunch:
    def __init__(self, dl_train, dl_valid, c):
        self.dl_train = dl_train
        self.dl_valid = dl_valid
        self.c = c

    @property
    def ds_train(self):
        return self.dl_train.dataset
    @property
    def ds_valid(self):
        return self.dl_valid.dataset

def get_model(data, lr=0.5, nh=50):
    n_in = data.ds_train.x.shape[1]
    model = nn.Sequential(nn.Linear(n_in, nh), nn.ReLU(), nn.Linear(nh, data.c))
    opt = optim.SGD(model.parameters(), lr)
    return model, opt

class Learner:
    def __init__(self, model, opt, loss_func, data):
        self.model = model
        self.opt = opt
        self.loss_func = loss_func
        self.data = data

import re

_camel_re1 = re.compile('(.)([A-Z][a-z]+)')
_camel_re2 = re.compile('([a-z0-9])([A-Z])')

def camel2snake(name):
    s1 = re.sub(_camel_re1, r'\1_\2', name)
    return re.sub(_camel_re2, r'\1_\2', s1).lower()

class Callback:
    _order = 0

    def set_runner(self, run):
        self.run = run

    def __getattr__(self, x):
        return getattr(self.run, x)

    @property
    def name(self):
        name = re.sub(r'Callback$', '', self.__class__.__name__)
        return camel2snake(name or 'callback')

class TrainEvalCallback(Callback):
    def begin_fit(self):
        self.run.n_epochs = 0
        self.run.n_iters = 0

    def after_batch(self):
        if not self.in_train: return
        self.run.n_epochs += 1./self.iters
        self.run.n_iters += 1

    def begin_epoch(self):
        self.run.n_epochs = self.epoch
        self.model.train()
        self.run.in_train = True

    def begin_validate(self):
        self.model.eval()
        self.run.in_train = False

from typing import *

def listify(o):
    if o is None: return []
    if isinstance(o, list): return o
    if isinstance(o, Iterable): return list(o)
    return [o]

class Runner:
    def __init__(self, cbs=None, cb_funcs=None):
        cbs = listify(cbs)
        for cbf in listify(cb_funcs):
            cb = cbf()
            setattr(self, cb.name, cb)
            cbs.append(cb)
        self.stop = False
        self.cbs = [TrainEvalCallback()] + cbs

    @property
    def opt(self):
        return self.learn.opt

    @property
    def model(self):
        return self.learn.model

    @property
    def loss_func(self):
        return self.learn.loss_func

    @property
    def data(self):
        return self.learn.data

    def one_batch(self, xb, yb):
        self.xb, self.yb = xb, yb

        if self('begin_batch'): return
        self.pred = self.model(self.xb)

        if self('after_pred'): return
        self.loss = self.loss_func(self.pred, self.yb)

        if self('after_loss') or not self.in_train: return
        self.loss.backward()

        if self('after_backward'): return
        self.opt.step()

        if self('after_step'): return
        self.opt.zero_grad()

    def all_batches(self, dl):
        self.iters = len(dl)

        for xb, yb in dl:
            if self.stop: break
            self.one_batch(xb, yb)
            self('after_batch')
        self.stop = False

    def fit(self, epochs, learn):
        self.epochs = epochs
        self.learn = learn
        try:

            for cb in self.cbs:
                cb.set_runner(self)

            if self('begin_fit'):
                return

            for epoch in range(epochs):
                self.epoch = epoch
                if not self('begin_epoch'):
                    self.all_batches(self.data.dl_train)

                with torch.no_grad():
                    if not self('begin_validate'):
                        self.all_batches(self.data.dl_valid)

                if self('after_epoch'):
                    break
        finally:
            self('after_fit')
            self.learn = None

    def __call__(self, cb_name):
        for cb in sorted(self.cbs, key=lambda x:x._order):
            f = getattr(cb, cb_name, None)
            if f and f():
                return True
        return False

class AvgStatsCallback(Callback):

    def __init__(self, metrics):
        self.train_stats = AvgStats(metrics, in_train=True)
        self.valid_stats = AvgStats(metrics, in_train=False)

    def begin_epoch(self):
        self.train_stats.reset()
        self.valid_stats.reset()

    def after_loss(self):
        stats = self.train_stats if self.in_train else self.valid_stats
        with torch.no_grad():
            stats.accumulate(self.run)

    def after_epoch(self):
        print(self.train_stats)
        print(self.valid_stats)

class AvgStats:
    def __init__(self, metrics, in_train):
        self.metrics = listify(metrics)
        self.in_train = in_train

    def reset(self):
        self.total_loss = 0
        self.count = 0
        self.total_metrics = [0.] * len(self.metrics)

    @property
    def all_stats(self):
        return [self.total_loss.item()] + self.total_metrics

    @property
    def avg_stats(self):
        return [o/self.count for o in self.all_stats]

    def __repr__(self):
        if not self.count: return ""
        return f"{'train' if self.in_train else 'valid'}: {self.avg_stats}"

    def accumulate(self, run):
        bn = run.xb.shape[0]
        self.total_loss += (bn * run.loss)
        self.count += bn
        for i, metric in enumerate(self.metrics):
            self.total_metrics[i] += metric(run.pred, run.yb) * bn