{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from exp.nb_03 import *\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File mnist.pkl.gz already exists in data\n"
     ]
    }
   ],
   "source": [
    "x_train,y_train,x_valid,y_valid = get_data()\n",
    "ds_train,ds_valid = Dataset(x_train, y_train),Dataset(x_valid, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "nh = 50\n",
    "bs = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = y_train.max().item() + 1\n",
    "loss_func = F.cross_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class DataBunch:\n",
    "    def __init__(self, dl_train, dl_valid, c):\n",
    "        self.dl_train = dl_train\n",
    "        self.dl_valid = dl_valid\n",
    "        self.c = c\n",
    "    \n",
    "    @property\n",
    "    def ds_train(self):\n",
    "        return self.dl_train.dataset\n",
    "    @property\n",
    "    def ds_valid(self):\n",
    "        return self.dl_valid.dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = DataBunch(*get_dls(ds_train, ds_valid, bs), 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def get_model(data, lr=0.5, nh=50):\n",
    "    n_in = data.ds_train.x.shape[1]\n",
    "    model = nn.Sequential(nn.Linear(n_in, nh), nn.ReLU(), nn.Linear(nh, data.c))\n",
    "    opt = optim.SGD(model.parameters(), lr)\n",
    "    return model, opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class Learner:\n",
    "    def __init__(self, model, opt, loss_func, data):\n",
    "        self.model = model\n",
    "        self.opt = opt\n",
    "        self.loss_func = loss_func\n",
    "        self.data = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, opt = get_model(data)\n",
    "learn = Learner(model, opt, loss_func, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.debugger import set_trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(epochs, learn):\n",
    "    for epoch in range(epochs):\n",
    "        learn.model.train()\n",
    "        for xb, yb in data.dl_train:\n",
    "            preds = learn.model(xb)\n",
    "            loss = learn.loss_func(preds, yb)\n",
    "            loss.backward()\n",
    "            learn.opt.step()\n",
    "            learn.opt.zero_grad()\n",
    "        \n",
    "        learn.model.eval()\n",
    "        tot_correct = tot_loss = tot_seen = 0\n",
    "        with torch.no_grad():\n",
    "            for xb, yb in learn.data.dl_valid:\n",
    "                preds = model(xb)\n",
    "                loss = learn.loss_func(preds, yb)\n",
    "                tot_correct += accuracy(preds, yb).item() * len(xb)\n",
    "                tot_loss += loss.item() * len(xb)\n",
    "                tot_seen += len(xb)\n",
    "            print(f\"Acc:{tot_correct/tot_seen:<10}| Loss:{(tot_loss/tot_seen)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc:0.9544    | Loss:0.15658490743637085\n",
      "Acc:0.9527    | Loss:0.1588026722729206\n",
      "Acc:0.9058    | Loss:0.3521318807423115\n",
      "Acc:0.9697    | Loss:0.1075203885935247\n",
      "Acc:0.9704    | Loss:0.10032944450825453\n"
     ]
    }
   ],
   "source": [
    "fit(5, learn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Callback Handler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Without callbacks\n",
    "def one_batch(xb,yb):\n",
    "    pred = model(xb)\n",
    "    loss = loss_func(pred, yb)\n",
    "    loss.backward()\n",
    "    opt.step()\n",
    "    opt.zero_grad()\n",
    "\n",
    "def fit():\n",
    "    for epoch in range(epochs):\n",
    "        for b in train_dl: one_batch(*b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def onebatch(xb, yb, cbh):\n",
    "    if not cbh.begin_batch(xb, yb): \n",
    "        return\n",
    "    preds = cbh.learn.model(xb)\n",
    "    loss = cbh.learn.loss_func(preds, yb)\n",
    "    if not cbh.in_train:\n",
    "        return\n",
    "    if not cbh.after_loss(loss):\n",
    "        return\n",
    "    loss.backward()\n",
    "    if cbh.after_backward():\n",
    "        cbh.learn.opt.step()\n",
    "    if cbh.after_step():\n",
    "        cbh.learn.opt.zero_grad()\n",
    "        \n",
    "def all_batches(dl, cbh):\n",
    "    for xb, yb in dl:\n",
    "        onebatch(xb, yb, cbh)\n",
    "        if cbh.do_stop():\n",
    "            return\n",
    "\n",
    "def fit(epochs, learn, cbh):\n",
    "    if not cbh.begin_fit(learn): \n",
    "        return\n",
    "    for epoch in range(epochs):\n",
    "        if not cbh.begin_epoch(epoch):\n",
    "            continue        \n",
    "        all_batches(learn.data.dl_train, cbh)\n",
    "        if cbh.begin_validate():\n",
    "            with torch.no_grad():\n",
    "                all_batches(learn.data.dl_valid, cbh)\n",
    "        if cbh.do_stop() or not cbh.after_epoch():\n",
    "            break\n",
    "    cbh.after_fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Callback():\n",
    "    def begin_fit(self, learn):\n",
    "        self.learn = learn\n",
    "        return True\n",
    "    def after_fit(self):\n",
    "        return True\n",
    "    def begin_epoch(self, epoch):\n",
    "        self.epoch = epoch\n",
    "        return True\n",
    "    def after_epoch(self):\n",
    "        return True\n",
    "    def begin_validate(self):\n",
    "        return True\n",
    "    def begin_batch(self, xb, yb):\n",
    "        self.xb = xb\n",
    "        self.yb = yb\n",
    "        return True\n",
    "    def after_loss(self, loss):\n",
    "        self.loss = loss\n",
    "        return True\n",
    "    def after_backward(self):\n",
    "        return True\n",
    "    def after_step(self):\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CallbackHandler():\n",
    "    def __init__(self, cbs):\n",
    "        self.cbs = cbs if cbs else []\n",
    "    \n",
    "    def begin_fit(self, learn):\n",
    "        self.learn = learn\n",
    "        self.in_train = True\n",
    "        learn.stop = False\n",
    "        res = True\n",
    "        for cb in self.cbs:\n",
    "            res = res and cb.begin_fit(learn)\n",
    "        return res\n",
    "    \n",
    "    def after_fit(self):\n",
    "        res = not self.in_train\n",
    "        for cb in self.cbs:\n",
    "            res = res and cb.after_fit()\n",
    "        return res\n",
    "    \n",
    "    def begin_epoch(self, epoch):\n",
    "        self.learn.model.train()\n",
    "        self.in_train = True\n",
    "        res = True\n",
    "        for cb in self.cbs:\n",
    "            res = res and cb.begin_epoch(epoch)\n",
    "        return res\n",
    "\n",
    "    def after_epoch(self):\n",
    "        res = True\n",
    "        for cb in self.cbs:\n",
    "            res = res and cb.after_epoch()\n",
    "        return res\n",
    "    \n",
    "    def begin_validate(self):\n",
    "        self.learn.model.eval()\n",
    "        self.in_train = False\n",
    "        res = True\n",
    "        for cb in self.cbs:\n",
    "            res = res and cb.begin_validate()\n",
    "        return res\n",
    "\n",
    "    def begin_batch(self, xb, yb):\n",
    "        res = True\n",
    "        for cb in self.cbs:\n",
    "            res = res and cb.begin_batch(xb, yb)\n",
    "        return res\n",
    "    \n",
    "    def after_loss(self, loss):\n",
    "        res = True\n",
    "        for cb in self.cbs:\n",
    "            res = res and cb.after_loss(loss)\n",
    "        return res\n",
    "\n",
    "    def after_backward(self):\n",
    "        res=True\n",
    "        for cb in self.cbs:\n",
    "            res = res and cb.after_backward()\n",
    "        return res\n",
    "\n",
    "    def after_step(self):\n",
    "        res = True\n",
    "        for cb in self.cbs:\n",
    "            res = res and cb.after_step()\n",
    "        return res\n",
    "\n",
    "    def do_stop(self):\n",
    "        try:\n",
    "            return self.learn.stop\n",
    "        finally:\n",
    "            self.learn.stop = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StopAfterTenItersCallback(Callback):\n",
    "    def begin_fit(self, learn):\n",
    "        self.n_iters = 0\n",
    "        super().begin_fit(learn)\n",
    "        return True\n",
    "    \n",
    "    def after_step(self):\n",
    "        self.n_iters += 1\n",
    "        if self.n_iters>=10:\n",
    "            self.learn.stop = True\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'StopAfterTenItersCallback' object has no attribute 'n_iter'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-e642bd04f40e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mcustom_callbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mStopAfterTenItersCallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcbh\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mCallbackHandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcustom_callbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-15-098f2aa30956>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(epochs, learn, cbh)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcbh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbegin_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0mall_batches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdl_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcbh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcbh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbegin_validate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-15-098f2aa30956>\u001b[0m in \u001b[0;36mall_batches\u001b[0;34m(dl, cbh)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mall_batches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcbh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdl\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0monebatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcbh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcbh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-15-098f2aa30956>\u001b[0m in \u001b[0;36monebatch\u001b[0;34m(xb, yb, cbh)\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcbh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mafter_backward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mcbh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mcbh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mafter_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0mcbh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-17-18cf59cd8126>\u001b[0m in \u001b[0;36mafter_step\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mcb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcbs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mafter_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-18-46c00be67bfc>\u001b[0m in \u001b[0;36mafter_step\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mafter_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_iters\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_iters\u001b[0m\u001b[0;34m>=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'StopAfterTenItersCallback' object has no attribute 'n_iter'"
     ]
    }
   ],
   "source": [
    "custom_callbacks = [StopAfterTenItersCallback()]\n",
    "fit(1, learn, cbh=CallbackHandler(custom_callbacks))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Runner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "import re\n",
    "\n",
    "_camel_re1 = re.compile('(.)([A-Z][a-z]+)')\n",
    "_camel_re2 = re.compile('([a-z0-9])([A-Z])')\n",
    "\n",
    "def camel2snake(name):\n",
    "    s1 = re.sub(_camel_re1, r'\\1_\\2', name)\n",
    "    return re.sub(_camel_re2, r'\\1_\\2', s1).lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class Callback:\n",
    "    _order = 0\n",
    "    \n",
    "    def set_runner(self, run):\n",
    "        self.run = run\n",
    "    \n",
    "    def __getattr__(self, x):\n",
    "        return getattr(self.run, x)\n",
    "    \n",
    "    @property\n",
    "    def name(self):\n",
    "        name = re.sub(r'Callback$', '', self.__class__.__name__)\n",
    "        return camel2snake(name or 'callback')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class TrainEvalCallback(Callback):\n",
    "    def begin_fit(self):\n",
    "        self.run.n_epochs = 0\n",
    "        self.run.n_iters = 0\n",
    "    \n",
    "    def after_batch(self):\n",
    "        if not self.in_train: return\n",
    "        self.run.n_epochs += 1./self.iters\n",
    "        self.run.n_iters += 1\n",
    "    \n",
    "    def begin_epoch(self):\n",
    "        self.run.n_epochs = self.epoch\n",
    "        self.model.train()\n",
    "        self.run.in_train = True\n",
    "    \n",
    "    def begin_validate(self):\n",
    "        self.model.eval()\n",
    "        self.run.in_train = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StopAfterTenIter(Callback):\n",
    "    def after_iter(self):\n",
    "        if self.train_eval.n_iters >= 10:\n",
    "            return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cbname = 'TrainEvalCallback'\n",
    "camel2snake(cbname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TrainEvalCallback.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TrainEvalCallback().name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "from typing import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def listify(o):\n",
    "    if o is None: return []\n",
    "    if isinstance(o, list): return o\n",
    "    if isinstance(o, Iterable): return list(o)\n",
    "    return [o]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class Runner:\n",
    "    def __init__(self, cbs=None, cb_funcs=None):\n",
    "        cbs = listify(cbs)\n",
    "        for cbf in listify(cb_funcs):\n",
    "            cb = cbf()\n",
    "            setattr(self, cb.name, cb)\n",
    "            cbs.append(cb)\n",
    "        self.stop = False\n",
    "        self.cbs = [TrainEvalCallback()] + cbs\n",
    "        \n",
    "    @property\n",
    "    def opt(self):\n",
    "        return self.learn.opt\n",
    "    \n",
    "    @property\n",
    "    def model(self):\n",
    "        return self.learn.model\n",
    "    \n",
    "    @property\n",
    "    def loss_func(self):\n",
    "        return self.learn.loss_func\n",
    "    \n",
    "    @property\n",
    "    def data(self):\n",
    "        return self.learn.data\n",
    "    \n",
    "    def one_batch(self, xb, yb):\n",
    "        self.xb, self.yb = xb, yb\n",
    "        \n",
    "        if self('begin_batch'): return\n",
    "        self.pred = self.model(self.xb)\n",
    "        \n",
    "        if self('after_pred'): return\n",
    "        self.loss = self.loss_func(self.pred, self.yb)\n",
    "        \n",
    "        if self('after_loss') or not self.in_train: return\n",
    "        self.loss.backward()\n",
    "        \n",
    "        if self('after_backward'): return\n",
    "        self.opt.step()\n",
    "        \n",
    "        if self('after_step'): return\n",
    "        self.opt.zero_grad()\n",
    "        \n",
    "    def all_batches(self, dl):\n",
    "        self.iters = len(dl)\n",
    "        \n",
    "        for xb, yb in dl:\n",
    "            if self.stop: break\n",
    "            self.one_batch(xb, yb)\n",
    "            self('after_batch')\n",
    "        self.stop = False\n",
    "        \n",
    "    def fit(self, epochs, learn):\n",
    "        self.epochs = epochs\n",
    "        self.learn = learn\n",
    "        try:\n",
    "\n",
    "            for cb in self.cbs:\n",
    "                cb.set_runner(self)\n",
    "\n",
    "            if self('begin_fit'):\n",
    "                return\n",
    "            \n",
    "            for epoch in range(epochs):\n",
    "                self.epoch = epoch\n",
    "                if not self('begin_epoch'):\n",
    "                    self.all_batches(self.data.dl_train)\n",
    "                \n",
    "                with torch.no_grad():\n",
    "                    if not self('begin_validate'):\n",
    "                        self.all_batches(self.data.dl_valid)\n",
    "                \n",
    "                if self('after_epoch'):\n",
    "                    break\n",
    "        finally:\n",
    "            self('after_fit')\n",
    "            self.learn = None\n",
    "            \n",
    "    def __call__(self, cb_name):\n",
    "        for cb in sorted(self.cbs, key=lambda x:x._order):\n",
    "            f = getattr(cb, cb_name, None)\n",
    "            if f and f():\n",
    "                return True\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class AvgStatsCallback(Callback):\n",
    "    \n",
    "    def __init__(self, metrics):\n",
    "        self.train_stats = AvgStats(metrics, in_train=True)\n",
    "        self.valid_stats = AvgStats(metrics, in_train=False)\n",
    "    \n",
    "    def begin_epoch(self):\n",
    "        self.train_stats.reset()\n",
    "        self.valid_stats.reset()\n",
    "    \n",
    "    def after_loss(self):\n",
    "        stats = self.train_stats if self.in_train else self.valid_stats\n",
    "        with torch.no_grad():\n",
    "            stats.accumulate(self.run)\n",
    "    \n",
    "    def after_epoch(self):\n",
    "        print(self.train_stats)\n",
    "        print(self.valid_stats)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class AvgStats:\n",
    "    def __init__(self, metrics, in_train):\n",
    "        self.metrics = listify(metrics)\n",
    "        self.in_train = in_train\n",
    "    \n",
    "    def reset(self):\n",
    "        self.total_loss = 0\n",
    "        self.count = 0\n",
    "        self.total_metrics = [0.] * len(self.metrics)\n",
    "    \n",
    "    @property\n",
    "    def all_stats(self):\n",
    "        return [self.total_loss.item()] + self.total_metrics\n",
    "    \n",
    "    @property\n",
    "    def avg_stats(self):\n",
    "        return [o/self.count for o in self.all_stats]\n",
    "    \n",
    "    def __repr__(self):\n",
    "        if not self.count: return \"\"\n",
    "        return f\"{'train' if self.in_train else 'valid'}: {self.avg_stats}\"\n",
    "    \n",
    "    def accumulate(self, run):\n",
    "        bn = run.xb.shape[0]\n",
    "        self.total_loss += (bn * run.loss)\n",
    "        self.count += bn\n",
    "        for i, metric in enumerate(self.metrics):\n",
    "            self.total_metrics[i] += metric(run.pred, run.yb) * bn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = Learner(*get_model(data), loss_func, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = AvgStatsCallback([accuracy])\n",
    "run = Runner(cbs=stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run.fit(5, learn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python notebook2script.py 04_callbacks.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
