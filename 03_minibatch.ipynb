{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import requests\n",
    "import pickle\n",
    "\n",
    "import gzip\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "MNIST_URL='http://deeplearning.net/data/mnist/mnist.pkl.gz'\n",
    "\n",
    "def download_file(url:str, folder:str):\n",
    "    folder = Path(folder)\n",
    "    files = [x.name for x in folder.glob('**/*') if x.is_file()]\n",
    "    filename = url.split('/')[-1]\n",
    "    if filename in files:\n",
    "        print(f\"File {filename} already exists in {folder}\")\n",
    "        return folder / filename\n",
    "    r = requests.get(url)\n",
    "    with open(folder / filename, 'wb') as f:\n",
    "        f.write(r.content)\n",
    "    return folder / filename\n",
    "\n",
    "def get_data():\n",
    "    path = download_file(MNIST_URL, './data')\n",
    "    with gzip.open(path, 'rb') as f:\n",
    "        ((x_train, y_train), (x_valid, y_valid), _) = pickle.load(f, encoding='latin-1')\n",
    "    return map(torch.tensor, (x_train,y_train,x_valid,y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File mnist.pkl.gz already exists in data\n"
     ]
    }
   ],
   "source": [
    "x_train,y_train,x_valid,y_valid = get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = x_train.shape[0]\n",
    "n_in = m = torch.tensor(x_train.shape[1:]).prod().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 784, 10)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_h = 50\n",
    "n_out = c = y_train.max().item() + 1\n",
    "n, m, c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, n_in, n_h, n_out):\n",
    "        super().__init__()\n",
    "        self.n_in = n_in\n",
    "        self.layers = [nn.Linear(n_in, n_h), nn.ReLU(), nn.Linear(n_h, n_out)]\n",
    "    \n",
    "    def __call__(self, x):\n",
    "        for l in self.layers: \n",
    "            x = l(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(m, n_h,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.4803, grad_fn=<MaxBackward1>),\n",
       " tensor(-0.4972, grad_fn=<MinBackward1>))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds.max(), preds.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_softmax(x):\n",
    "    return (x.exp()/(x.exp().sum(-1,keepdim=True))).log()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "lsm_pred = log_softmax(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nll(input, target):\n",
    "    return -input[range(input.shape[0]), target].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.3096, grad_fn=<NegBackward>)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = nll(lsm_pred, y_train)\n",
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "vanishes due to exp overflow/underflow in log_softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logsumexp(x):\n",
    "    max_ = x.max(-1)[0] # values not indices\n",
    "    return max_ + (x - max_[:, None]).exp().sum(-1).log()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_softmax2(x): \n",
    "    return x - x.logsumexp(-1,keepdim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.3096, grad_fn=<NegBackward>)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lsm_pred = log_softmax2(preds)\n",
    "loss = nll(lsm_pred, y_train)\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50000])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logsumexp(preds).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.3096, grad_fn=<NllLossBackward>)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lsm_preds = F.log_softmax(preds, -1)\n",
    "F.nll_loss(lsm_pred, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.3096, grad_fn=<NllLossBackward>)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.cross_entropy(preds, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = F.cross_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def accuracy(preds, target):\n",
    "    return (preds.argmax(axis=1) == target).float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.1325)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(preds, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 64\n",
    "\n",
    "xb = x_train[:bs]\n",
    "yb = y_train[:bs]\n",
    "\n",
    "preds = model(xb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.3349, grad_fn=<NllLossBackward>)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_func(preds, yb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0625)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(preds, yb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "lr = 0.01\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for i in range( (n-1)//bs +1):\n",
    "        start_i = bs*i\n",
    "        end_i = start_i + bs\n",
    "        xb = x_train[start_i:end_i]\n",
    "        yb = y_train[start_i:end_i]\n",
    "        preds = model(xb)\n",
    "        loss = loss_func(preds, yb)\n",
    "        \n",
    "        loss.backward()\n",
    "        with torch.no_grad():\n",
    "            for l in model.layers:\n",
    "                if hasattr(l, 'weight'):\n",
    "                    l.weight -= lr * l.weight.grad\n",
    "                    l.weight.grad.zero_()\n",
    "                    l.bias -= lr * l.bias.grad\n",
    "                    l.bias.grad.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.3736, grad_fn=<NllLossBackward>)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_func(model(xb), yb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.8750)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(model(xb), yb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DummyModule():\n",
    "    def __init__(self, nin, nh, nout):\n",
    "        self._modules = {}\n",
    "        self.l1 = nn.Linear(nin, nh)\n",
    "        self.l2 = nn.Linear(nh, nout)\n",
    "    \n",
    "    def __setattr__(self, k, v):\n",
    "        if not k.startswith(\"_\"): self._modules[k] = v\n",
    "        super().__setattr__(k, v)\n",
    "        \n",
    "    def __repr__(self): return f\"{self._modules}\"\n",
    "    \n",
    "    def parameters(self):\n",
    "        for l in self._modules.values():\n",
    "            for p in l.parameters(): yield p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'l1': Linear(in_features=784, out_features=50, bias=True), 'l2': Linear(in_features=50, out_features=10, bias=True)}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2 = DummyModule(n_in, n_h, n_out)\n",
    "model2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object DummyModule.parameters at 0x7f192d845360>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[torch.Size([50, 784]),\n",
       " torch.Size([50]),\n",
       " torch.Size([10, 50]),\n",
       " torch.Size([10])]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list([x.shape for x in model2.parameters()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, nin, nh, nout):\n",
    "        super().__init__()\n",
    "        self.l1 = nn.Linear(nin, nh)\n",
    "        self.l2 = nn.Linear(nh, nout)\n",
    "        \n",
    "    def __call__(self, x):\n",
    "        return self.l2(F.relu(self.l1(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('l1', Linear(in_features=784, out_features=50, bias=True)),\n",
       " ('l2', Linear(in_features=50, out_features=10, bias=True))]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Model(n_in, n_h, n_out)\n",
    "list(model.named_children())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.2898, grad_fn=<NllLossBackward>)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_func(model(xb), yb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "lr = 0.01\n",
    "\n",
    "def fit():\n",
    "    for epoch in range(epochs):\n",
    "        for i in range( (n-1)//bs +1):\n",
    "            start_i = bs*i\n",
    "            end_i = start_i + bs\n",
    "            xb = x_train[start_i:end_i]\n",
    "            yb = y_train[start_i:end_i]\n",
    "            preds = model(xb)\n",
    "            loss = loss_func(preds, yb)\n",
    "\n",
    "            loss.backward()\n",
    "            with torch.no_grad():\n",
    "                for p in model.parameters():\n",
    "                    p -= lr * p.grad\n",
    "                model.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stats():\n",
    "    return loss_func(model(xb), yb), accuracy(model(xb), yb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(2.2898, grad_fn=<NllLossBackward>), tensor(0.0625))"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.3843, grad_fn=<NllLossBackward>), tensor(0.8750))"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit(); stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Registering modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = [nn.Linear(n_in, n_h), nn.ReLU(), nn.Linear(n_h, n_out)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    \n",
    "    def __init__(self, layers):\n",
    "        super().__init__()\n",
    "        self.layers = layers\n",
    "        for i, l in enumerate(layers):\n",
    "            self.add_module(f'layer_{i}', l)\n",
    "    \n",
    "    def __call__(self, x):\n",
    "        for l in self.layers:\n",
    "            x = l(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(2.3190, grad_fn=<NllLossBackward>), tensor(0.0625))"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Model(layers)\n",
    "stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.3933, grad_fn=<NllLossBackward>), tensor(0.8750))"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit()\n",
    "stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SequentialModel(nn.Module):\n",
    "    def __init__(self, layers):\n",
    "        super().__init__()\n",
    "        self.layers = nn.ModuleList(layers)\n",
    "    \n",
    "    def __call__(self, x):\n",
    "        for l in self.layers:\n",
    "            x = l(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.3933, grad_fn=<NllLossBackward>), tensor(0.8750))"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = SequentialModel(layers)\n",
    "stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.2274, grad_fn=<NllLossBackward>), tensor(0.8750))"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit(); stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(nn.Linear(n_in,n_h), nn.ReLU(), nn.Linear(n_h, n_out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.3848, grad_fn=<NllLossBackward>), tensor(0.8750))"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit(); stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=784, out_features=50, bias=True)\n",
       "  (1): ReLU()\n",
       "  (2): Linear(in_features=50, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Optimizer:\n",
    "\n",
    "    def __init__(self, params, lr):\n",
    "        self.params = list(params)\n",
    "        self.lr = lr\n",
    "    \n",
    "    def step(self):\n",
    "        with torch.no_grad():\n",
    "            for p in self.params:\n",
    "                p -= p.grad * self.lr\n",
    "    \n",
    "    def zero_grad(self):\n",
    "        with torch.no_grad():\n",
    "            for p in self.params:\n",
    "                p.grad.data.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(nn.Linear(n_in,n_h), nn.ReLU(), nn.Linear(n_h, n_out))\n",
    "opt = Optimizer(model.parameters(), 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit():\n",
    "    for epoch in range(epochs):\n",
    "        for i in range((n-1)//bs + 1):\n",
    "            start_i = i*bs\n",
    "            end_i = start_i+bs\n",
    "            xb = x_train[start_i:end_i]\n",
    "            yb = y_train[start_i:end_i]\n",
    "            pred = model(xb)\n",
    "            loss = loss_func(pred, yb)\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            opt.zero_grad()\n",
    "        print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(2.2614, grad_fn=<NllLossBackward>), tensor(0.2500))"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.0969, grad_fn=<NllLossBackward>)\n",
      "tensor(0.8751, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7757, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7055, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6514, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6057, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5656, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5303, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5004, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4737, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor(0.4101, grad_fn=<NllLossBackward>), tensor(0.8750))"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit(); stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSGD\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclosure\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mSource:\u001b[0m   \n",
       "    \u001b[0;32mdef\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclosure\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;34m\"\"\"Performs a single optimization step.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m        Arguments:\u001b[0m\n",
       "\u001b[0;34m            closure (callable, optional): A closure that reevaluates the model\u001b[0m\n",
       "\u001b[0;34m                and returns the loss.\u001b[0m\n",
       "\u001b[0;34m        \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mclosure\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclosure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mfor\u001b[0m \u001b[0mgroup\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_groups\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mweight_decay\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'weight_decay'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mmomentum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'momentum'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mdampening\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'dampening'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mnesterov\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'nesterov'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'params'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0;32mif\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                    \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0md_p\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0;32mif\u001b[0m \u001b[0mweight_decay\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                    \u001b[0md_p\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight_decay\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0;32mif\u001b[0m \u001b[0mmomentum\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                    \u001b[0mparam_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                    \u001b[0;32mif\u001b[0m \u001b[0;34m'momentum_buffer'\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparam_state\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                        \u001b[0mbuf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparam_state\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'momentum_buffer'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md_p\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                    \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                        \u001b[0mbuf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparam_state\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'momentum_buffer'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                        \u001b[0mbuf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmomentum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mdampening\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_p\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                    \u001b[0;32mif\u001b[0m \u001b[0mnesterov\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                        \u001b[0md_p\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0md_p\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmomentum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                    \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                        \u001b[0md_p\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lr'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_p\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mFile:\u001b[0m      ~/.local/share/virtualenvs/v3-part-2-HzV0j99G/lib/python3.6/site-packages/torch/optim/sgd.py\n",
       "\u001b[0;31mType:\u001b[0m      function\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "optim.SGD.step??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    model = nn.Sequential(nn.Linear(n_in, n_h), nn.ReLU(), nn.Linear(n_h, n_out))\n",
    "    opt = optim.SGD(model.parameters(), lr=lr)\n",
    "    return model, opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = nn.CrossEntropyLoss()\n",
    "epochs = 10\n",
    "bs = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, opt = get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss_func(model(xb), yb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CrossEntropyLoss()"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(epochs):\n",
    "    for i in range((n-1)//bs + 1):\n",
    "        start_i = i*bs\n",
    "        end_i = start_i+bs\n",
    "        xb = x_train[start_i:end_i]\n",
    "        yb = y_train[start_i:end_i]\n",
    "        pred = model(xb)\n",
    "        loss = loss_func(pred, yb)\n",
    "\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(model(xb), yb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class Dataset:\n",
    "    def __init__(self, x, y):\n",
    "        assert len(x)==len(y)\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "    def __getitem__(self, i):\n",
    "        return self.x[i], self.y[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train = Dataset(x_train, y_train)\n",
    "ds_valid  = Dataset(x_valid, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(ds_train)==len(x_train)\n",
    "assert len(ds_valid)==len(x_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 784]) torch.Size([5])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]]), tensor([5, 0, 4, 1, 9]))"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xb, yb = ds_train[:5]\n",
    "print(xb.shape, yb.shape)\n",
    "xb, yb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, opt = get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.0223, -0.0324,  0.0028,  ...,  0.0215, -0.0295,  0.0183],\n",
       "        [ 0.0086,  0.0311, -0.0220,  ...,  0.0215, -0.0156,  0.0134],\n",
       "        [ 0.0014, -0.0225, -0.0353,  ...,  0.0025, -0.0323,  0.0171],\n",
       "        ...,\n",
       "        [ 0.0067,  0.0185, -0.0218,  ...,  0.0211,  0.0048,  0.0042],\n",
       "        [ 0.0294,  0.0150, -0.0265,  ..., -0.0249,  0.0013,  0.0171],\n",
       "        [ 0.0338,  0.0145,  0.0082,  ...,  0.0260,  0.0077,  0.0325]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(model.parameters())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(epochs):\n",
    "    for i in range((n-1)//bs + 1):\n",
    "        xb, yb = ds_train[i*bs:i*bs+bs]\n",
    "        pred = model(xb)\n",
    "        loss = loss_func(pred, yb)\n",
    "        \n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(model(xb), yb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataLoader:\n",
    "    def __init__(self, ds, bs):\n",
    "        self.ds = ds\n",
    "        self.bs = bs\n",
    "    def __len__(self):\n",
    "        return len(self.ds)\n",
    "    def __iter__(self):\n",
    "        for i in range(0, len(self.ds), self.bs):\n",
    "            yield self.ds[i:i+self.bs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl_train = DataLoader(ds_train, bs)\n",
    "dl_valid = DataLoader(ds_valid, bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, opt = get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(model(xb), yb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit():\n",
    "    for epoch in range(epochs):\n",
    "        for (xb, yb) in dl_train:\n",
    "            pred = model(xb)\n",
    "            loss = loss_func(pred, yb)\n",
    "\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            opt.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.0031, grad_fn=<NllLossBackward>), tensor(1.))"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit(); stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4, 3, 2, 1, 9, 7, 0, 8, 5, 6])"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.randperm(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sampler:\n",
    "    def __init__(self, ds, bs, shuffle):\n",
    "        self.n = len(ds)\n",
    "        self.bs = bs\n",
    "        self.shuffle = shuffle\n",
    "    def __iter__(self):\n",
    "        idxs = torch.randperm(self.n) if self.shuffle else torch.arange(self.n)\n",
    "        for i in range(0, self.n, self.bs):\n",
    "            yield idxs[i:i+self.bs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shuffle [tensor([0, 9, 1]), tensor([5, 7, 2]), tensor([6, 8, 3]), tensor([4])]\n",
      "No Shuffle [tensor([0, 1, 2]), tensor([3, 4, 5]), tensor([6, 7, 8]), tensor([9])]\n"
     ]
    }
   ],
   "source": [
    "ds_small = Dataset(*ds_train[:10])\n",
    "sampler = Sampler(ds_small, 3, True)\n",
    "print(\"Shuffle\", [x for x in sampler])\n",
    "sampler = Sampler(ds_small, 3, False)\n",
    "print(\"No Shuffle\", [x for x in sampler])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataLoader:\n",
    "    def __init__(self, ds, sampler):\n",
    "        self.ds = ds\n",
    "        self.sampler = sampler\n",
    "    def __len__(self):\n",
    "        return len(self.ds)\n",
    "    def __iter__(self):\n",
    "        for i in self.sampler:\n",
    "            yield self.ds[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "it = iter(DataLoader(ds_small, sampler))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[torch.Size([3, 784]), torch.Size([3])]"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = next(it)\n",
    "[x.shape for x in n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(b):\n",
    "    xs, ys = zip(*b)\n",
    "    return torch.stack(xs), torch.stack(ys)\n",
    "\n",
    "class DataLoader:\n",
    "    def __init__(self, ds, sampler, collate_fn=collate_fn):\n",
    "        self.ds = ds\n",
    "        self.sampler = sampler\n",
    "    def __len__(self):\n",
    "        return len(self.ds)\n",
    "    def __iter__(self):\n",
    "        for s in self.sampler:\n",
    "            yield collate_fn([self.ds[i] for i in s])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "it = iter(DataLoader(ds_small, sampler))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 784]), torch.Size([3]))"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = next(it)\n",
    "n[0].shape, n[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "samp_train = Sampler(ds_train, bs, True)\n",
    "samp_valid = Sampler(ds_valid, bs, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl_train = DataLoader(ds_train, samp_train, collate_fn)\n",
    "dl_valid = DataLoader(ds_valid, samp_valid, collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3)"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "xb, yb = next(iter(dl_valid))\n",
    "plt.imshow(xb[0].view(28,28))\n",
    "yb[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3)"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "xb, yb = next(iter(dl_valid))\n",
    "plt.imshow(xb[0].view(28,28))\n",
    "yb[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3)"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "xb, yb = next(iter(dl_train))\n",
    "plt.imshow(xb[0].view(28,28))\n",
    "yb[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(9)"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "xb, yb = next(iter(dl_train))\n",
    "plt.imshow(xb[0].view(28,28))\n",
    "yb[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pytorch DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "from torch.utils.data import DataLoader, SequentialSampler, RandomSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl_train = DataLoader(ds_train, bs, sampler=RandomSampler(ds_train), collate_fn=collate_fn)\n",
    "dl_valid = DataLoader(ds_valid, bs, sampler=SequentialSampler(ds_valid), collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.1202, grad_fn=<NllLossBackward>), tensor(0.9531))"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model,opt = get_model()\n",
    "fit(); stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl_train = DataLoader(ds_train, bs, shuffle=True, drop_last=True)\n",
    "dl_valid = DataLoader(ds_valid, bs, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.1044, grad_fn=<NllLossBackward>), tensor(0.9688))"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model,opt = get_model()\n",
    "fit();stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(model, epochs, loss_func, opt, dl_train, dl_valid):\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        for xb, yb in dl_train:\n",
    "            preds = model(xb)\n",
    "            loss = loss_func(preds, yb)\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            opt.zero_grad()\n",
    "        \n",
    "        model.eval()\n",
    "        tot_correct = tot_loss = tot_seen = 0\n",
    "        with torch.no_grad():\n",
    "            for xb, yb in dl_valid:\n",
    "                preds = model(xb)\n",
    "                loss = loss_func(preds, yb)\n",
    "                tot_correct += accuracy(preds, yb).item() * len(xb)\n",
    "                tot_loss += loss.item() * len(xb)\n",
    "                tot_seen += len(xb)\n",
    "            print(f\"Acc:{tot_correct/tot_seen:<10}| Loss:{(tot_loss/tot_seen)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc:0.9247    | Loss:0.26583040053844453\n",
      "Acc:0.9413    | Loss:0.20672331719398498\n",
      "Acc:0.9498    | Loss:0.1762784543633461\n",
      "Acc:0.9538    | Loss:0.15970345425605775\n",
      "Acc:0.9606    | Loss:0.14108693509697914\n",
      "Acc:0.9621    | Loss:0.13135480370521546\n",
      "Acc:0.9661    | Loss:0.1209052057504654\n",
      "Acc:0.9687    | Loss:0.11313683553338051\n",
      "Acc:0.9688    | Loss:0.11137832363545895\n",
      "Acc:0.9694    | Loss:0.10753029338568448\n"
     ]
    }
   ],
   "source": [
    "model, opt = get_model()\n",
    "fit(model, 10, nn.CrossEntropyLoss(), opt, dl_train, dl_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def get_dls(ds_train, ds_valid, bs, **kwargs):\n",
    "    return (DataLoader(ds_train, batch_size=bs, shuffle=True, **kwargs),\n",
    "            DataLoader(ds_valid, batch_size=bs*2, **kwargs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc:0.9076    | Loss:0.31090502943992615\n",
      "Acc:0.9368    | Loss:0.22862556113004684\n",
      "Acc:0.9397    | Loss:0.21108992350697517\n",
      "Acc:0.9566    | Loss:0.15490732422471046\n",
      "Acc:0.9604    | Loss:0.14133806959986686\n"
     ]
    }
   ],
   "source": [
    "dl_train, dl_valid = get_dls(ds_train, ds_valid, bs)\n",
    "model, opt = get_model()\n",
    "fit(model, 5, nn.CrossEntropyLoss(), opt, dl_train, dl_valid)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 03_minibatch.ipynb to exp/nb_03.py\n"
     ]
    }
   ],
   "source": [
    "!python notebook2script.py 03_minibatch.ipynb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
